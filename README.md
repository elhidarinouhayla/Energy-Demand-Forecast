# Energy-Demand-Forecast

##  Description du Projet

Ce projet impl√©mente un mod√®le LSTM (Long Short-Term Memory) pour pr√©dire la consommation √©lectrique horaire d'un r√©seau intelligent (Smart Grid) g√©r√© par la start-up **EcoVolt**.

L'objectif est d'anticiper la consommation de l'heure suivante (t+1) √† partir des 24 heures pr√©c√©dentes, en tenant compte du mix √©nerg√©tique (nucl√©aire, solaire, √©olien, etc.).

---

##  Objectifs P√©dagogiques

- Comprendre le fonctionnement des r√©seaux de neurones r√©currents (RNN)
- Impl√©menter un mod√®le LSTM multivari√© sur s√©ries temporelles
- Ma√Ætriser le preprocessing sp√©cifique aux donn√©es temporelles
- Justifier les choix d'architecture et d'√©valuation

---

##  Dataset

Le dataset contient des mesures horaires avec les colonnes suivantes :

### Variable cible
- **Consumption** : Consommation √©lectrique totale (MW)

### Variables explicatives
- **Production** : Production totale
- **Nuclear** : Production nucl√©aire
- **Wind** : Production √©olienne
- **Solar** : Production solaire
- **Hydroelectric** : Production hydro√©lectrique
- **Coal** : Production charbon
- **Oil and Gas** : Production p√©trole et gaz
- **Biomass** : Production biomasse

### M√©tadonn√©es
- **DateTime** : Date et heure de la mesure (granularit√© horaire)

---

## üõ†Ô∏è Technologies Utilis√©es

```python
- Python 3.x
- TensorFlow / Keras
- Pandas
- NumPy
- Scikit-learn
- Matplotlib
```

---

##  Structure du Projet

```
EcoVolt-LSTM-Prediction/
‚îÇ
‚îú‚îÄ‚îÄ dataset/
‚îÇ   ‚îî‚îÄ‚îÄ energy_consumption.csv
‚îÇ
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ EcoVolt_LSTM_Prediction.ipynb
‚îÇ
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ requirements.txt
```

---

##  Installation et Ex√©cution





 **Cloner le repository** :
   ```bash
   git clone https://github.com/elhidarinouhayla/Energy-Demand-Forecast.git
   cd Energy-Demand-Forecast
   ```


---

##  M√©thodologie

### 1. Pr√©paration des Donn√©es
- Conversion de `DateTime` en index temporel
- Tri chronologique des donn√©es (pas de shuffle !)
- Normalisation avec `MinMaxScaler` (√©chelle [0,1])

### 2. Cr√©ation des S√©quences
- Fen√™tre glissante de **24 heures**
- Format 3D : (samples, timesteps, features)
- Exemple : (10000, 24, 9) = 10000 s√©quences de 24h avec 9 variables

### 3. Split Train/Test Temporel
- **80%** pour l'entra√Ænement (donn√©es pass√©es)
- **20%** pour le test (donn√©es futures)
- Pas de m√©lange al√©atoire pour √©viter la fuite de donn√©es

### 4. Architecture LSTM


### 5. Entra√Ænement
- **Optimizer** : Adam
- **Loss** : MSE (Mean Squared Error)
- **Epochs** : 30
- **Batch size** : 32
- **Validation split** : 20%

---

## R√©sultats

### Performances du Mod√®le

| M√©trique | Valeur |
|----------|--------|
| **Train Loss (final)** | 4.21e-04 |
| **Val Loss (final)** | 2.79e-04 |
| **Temps d'entra√Ænement** | ~8-9 minutes (30 epochs) |

### √âvolution de l'Entra√Ænement

```
Epoch 1/30  : loss: 0.0191 - val_loss: 0.0027
Epoch 10/30 : loss: 6.96e-04 - val_loss: 4.32e-04
Epoch 20/30 : loss: 4.79e-04 - val_loss: 3.73e-04
Epoch 30/30 : loss: 4.21e-04 - val_loss: 2.92e-04
```

### Observations
**Convergence rapide** : Loss divis√©e par 45 en 30 epochs  
**Bonne g√©n√©ralisation** : Val_loss l√©g√®rement inf√©rieur au train_loss  
**L√©g√®res oscillations** : Entre epochs 11-28 (peut b√©n√©ficier d'Early Stopping)

### Visualisation

Le graphique **R√©el vs Pr√©dit** montre une superposition quasi-parfaite des courbes, indiquant que le mod√®le capture excellemment :
- Les cycles journaliers de consommation
- Les pics de demande
- Les variations li√©es au mix √©nerg√©tique
